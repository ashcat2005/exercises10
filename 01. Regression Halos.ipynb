{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"01. Regression Halos.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"yaYD--6FffEM"},"source":["# Computational Astrophysics 2021\n","---\n","## Eduard Larrañaga\n","\n","Observatorio Astronómico Nacional\\\n","Facultad de Ciencias\\\n","Universidad Nacional de Colombia\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"oRIl-TKTfjKU"},"source":["## Exercise. Linear Regression using `SciKit Learn`\n","\n","### About this notebook\n","\n","In this exercise, you will analize some data from the Bolshoi simulation to find linear correlations between some variables. \n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"b0h5kwjiOPOq"},"source":["## Regression with dark matter halos\n","\n","In this tutorial, you will practice how to carry out a simple regression task. The first step is to download a public dark matter halo catalogue from the Bolshoi simulation. It can be found at\n","\n","http://www.slac.stanford.edu/~behroozi/Bolshoi_Catalogs/  \n","\n","The catalogue at z=0 is named 'hlist_1.00035.list.gz'. Once it is unziped, the size of the datafile is about 8Gb and contains millions of samples. In order to illustrate the analysis of the data, a reduced version of this file, with approximately 21000 samples, is given with this notebook. This file is called 'bolshoi01.list' \n","\n","Complete information about the Bolshoi simulation can be found in the paper\n","\n","A. Klypin, S. Trujillo-Gomez, J. Primack. *Halos and galaxies in the standard cosmological model: results from the Bolshoi simulation.*\n","https://arxiv.org/abs/1002.3660"]},{"cell_type":"code","metadata":{"id":"hlXeSl4UnG1I"},"source":["path='' #Define an empty string to use in case of local working"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"goa_zbFXnJMu","executionInfo":{"status":"ok","timestamp":1611768698536,"user_tz":300,"elapsed":18571,"user":{"displayName":"Eduard Alexis Larranaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64","userId":"04402438389940282602"}},"outputId":"9abb0096-e1f4-4dc2-8e15-7731ae28add0"},"source":["# Working with google colab needs to mount the Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d00C62iKnP-n"},"source":["# we define the path to the files\n","path = '/content/drive/MyDrive/Colab Notebooks/CA2021/10. Regression II/exercises/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSObhji7OPOu"},"source":["#Import modules\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","#Plot in cells\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m1JsAaGIOPOu"},"source":["### Loading the data\n","\n","In order to load the data from the file, we will use the function `numpy.genfromtxt()` which is similar to the function `numpy.loadtxt()`, that we have used before, but gives some options that help when dealing with missing values. Complete information about this function is found at\n","\n","https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html\n","\n","We will load the first 20000 samples."]},{"cell_type":"code","metadata":{"id":"fTuLAQ4UOPOu"},"source":["#Load data from ascii file\n","data = np.genfromtxt(path+\"bolshoi01.list\",comments='#',max_rows=20000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wSOW1s1h3yN7"},"source":["From the header of the datafile, you can identify the features included. Some of them are"]},{"cell_type":"markdown","metadata":{"id":"fyjW830_pxQT"},"source":["| Column | Feature |\n","|---|:--|\n","|10| Mvir: Halo mass (Msun/h)|\n","|11| Rvir: Halo radius (kpc/h comoving)|\n","|12| Rs: Scale radius (kpc/h comoving)|\n","|13| Vrms: Velocity dispersion (km/s physical)|\n","|14| mmp?: whether the halo is the most massive progenitor or not|\n","|15| scale_of_last_MM: scale factor of the last major merger (Mass ratio > 0.3)|\n","|16| Vmax: Maxmimum circular velocity (km/s physical)|\n","|17:19| X / Y / Z: Halo position (Mpc/h comoving)|\n","|20:22| VX / VY / VZ: Halo velocity (km/s physical)|\n","|23:25| JX / JY / JZ: Halo angular momenta ((Msun/h) * (Mpc/h) * km/s (physical))|\n","|26| Spin: Halo spin parameter|\n","|27| Breadth_first_ID: breadth-first ordering of halos within a tree|\n","|28| Depth_first_ID: depth-first ordering of halos within a tree|\n","|29| Tree_root_ID: ID of the halo at the last timestep in the tree|\n","|30| Orig_halo_ID: Original halo ID from halo finder|\n","|31| Snap_num: Snapshot number from which halo originated|\n","|32| Next_coprogenitor_depthfirst_ID: Depthfirst ID of next coprogenitor|\n","|33| Last_progenitor_depthfirst_ID: Depthfirst ID of last progenitor|\n","|34| Last_mainleaf_depthfirst_ID: Depthfirst ID of last progenitor on main progenitor branch|\n","|35| Rs_Klypin: Scale radius determined using Vmax and Mvir (see Rockstar paper)|\n","|36| Mvir_all: Mass enclosed within the specified overdensity, including unbound particles (Msun/h)|\n","|37:40| M200b--M2500c: Mass enclosed within specified overdensities (Msun/h)|\n","|41| Xoff: Offset of density peak from average particle position (kpc/h comoving)|\n","|42| Voff: Offset of density peak from average particle velocity (km/s physical)|\n","|43| Spin_Bullock: Bullock spin parameter (J/(sqrt(2)*GMVR))|\n","|44:45| b_to_a, c_to_a: Ratio of second and third largest shape ellipsoid axes (B and C) to largest shape ellipsoid axis (A) (dimensionless).<br> Shapes are determined by the method in Allgood et al. (2006)|\n","|46:48| A[x],A[y],A[z]: Largest shape ellipsoid axis (kpc/h comoving)|\n","|49:50| b_to_a, c_to_a: Ratio of second and third largest shape ellipsoid axes (B and C) to largest shape ellipsoid axis (A) (dimensionless).<br> Shapes are determined by the method in Allgood et al. (2006). <br>(500c) indicates that only particles within R500c are considered|\n","|51:53| A[x],A[y],A[z]: Largest shape ellipsoid axis (kpc/h comoving).<br>(500c) indicates that only particles within R500c are considered|\n","|54| T/\\|U\\|: ratio of kinetic to potential energies|\n","|55:56| M_pe_*: Pseudo-evolution corrected masses (very experimental).Consistent Trees Version 1.0+. Includes fix for Rockstar spins & T/|U| (assuming T/|U| = column 53)|\n","|57|Macc: Mass at accretion|\n","|58|Mpeak: Peak mass over mass accretion history1|\n","|59|Vacc: Vmax at accretion|\n","|60|Vpeak: Peak Vmax over mass accretion history1|\n","|61|Halfmass_Scale: Scale factor at which the MMP reaches 0.5*Mpeak|\n","|62:64|Acc_Rate_\\*: Halo mass accretion rates in Msun / h / yr <br>Inst: instantaneous; 100Myr: averaged over past 100Myr <br>X\\*Tdyn: averaged over past X*virial dynamical time <br>Mpeak: Growth Rate of Mpeak, averaged from current z to z+0.5|"]},{"cell_type":"markdown","metadata":{"id":"o_B1BaSX4fIO"},"source":["Now, we will extract some of these properties. (Since we are using machine learning, we will call the halo properties from now on 'features')."]},{"cell_type":"code","metadata":{"id":"mG89VB8XOPOu"},"source":["#Define halo properties\n","#Each column gives us a different halo property. Here we define all those properties we want to use.\n","#If you feal like adding some more properties, try it out...\n","virial_mass   = np.log10(data[:,10])\n","virial_radius = np.log10(data[:,11])\n","concentration = np.log10(data[:,11] / data[:,12]) #Concentration is virial radius divided by scale length\n","velocity_disp = np.log10(data[:,13])\n","vmax          = np.log10(data[:,16])\n","spin          = np.log10(data[:,26])\n","b_to_a        = data[:,44]\n","c_to_a        = data[:,45]\n","energy_ratio  = data[:,54]\n","peak_mass     = np.log10(data[:,58])\n","peak_vmax     = np.log10(data[:,60])\n","halfmass_a    = data[:,61]\n","peakmass_a    = data[:,67]\n","acc_rate      = data[:,64]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0WxWrvuoRzf"},"source":["You will then use the Pandas library to analyse this halo catalogue and to identify correlation between different halo properties. \n","\n","**1. Define a dataframe including the features describing the halos.**\n"]},{"cell_type":"code","metadata":{"id":"5gefI99v4vnk","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1611781367830,"user_tz":300,"elapsed":1119,"user":{"displayName":"Eduard Alexis Larranaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64","userId":"04402438389940282602"}},"outputId":"5ef8de02-dd0f-4e04-a4db-0c2864aa353c"},"source":["#Create Pandas Data Frame\n","#For easier handling we use the Pandas library.\n","#The following lines load all halo properties into a Pandas data frame called halos.\n","#Add all halo properties here:\n","halos = pd.DataFrame({\n","    'Virial Mass':virial_mass,\n","    'Virial Radius':virial_radius,\n","    'Concentration':concentration,\n","    'Vel. Dispersion':velocity_disp,\n","#Add the other quantities here!\n","})\n","halos"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Virial Mass</th>\n","      <th>Virial Radius</th>\n","      <th>Concentration</th>\n","      <th>Vel. Dispersion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14.215638</td>\n","      <td>3.054453</td>\n","      <td>1.001863</td>\n","      <td>2.984820</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>14.201124</td>\n","      <td>3.049566</td>\n","      <td>0.699512</td>\n","      <td>2.947919</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>14.058426</td>\n","      <td>3.001994</td>\n","      <td>0.889922</td>\n","      <td>2.907191</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13.987175</td>\n","      <td>2.978264</td>\n","      <td>0.479754</td>\n","      <td>2.879302</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13.930796</td>\n","      <td>2.959464</td>\n","      <td>0.898464</td>\n","      <td>2.872739</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19995</th>\n","      <td>10.283753</td>\n","      <td>1.743768</td>\n","      <td>1.431168</td>\n","      <td>1.718585</td>\n","    </tr>\n","    <tr>\n","      <th>19996</th>\n","      <td>10.283753</td>\n","      <td>1.743768</td>\n","      <td>1.435631</td>\n","      <td>1.678427</td>\n","    </tr>\n","    <tr>\n","      <th>19997</th>\n","      <td>10.283753</td>\n","      <td>1.743768</td>\n","      <td>1.133534</td>\n","      <td>1.609914</td>\n","    </tr>\n","    <tr>\n","      <th>19998</th>\n","      <td>10.283753</td>\n","      <td>1.743768</td>\n","      <td>1.050305</td>\n","      <td>1.632862</td>\n","    </tr>\n","    <tr>\n","      <th>19999</th>\n","      <td>10.283753</td>\n","      <td>1.743768</td>\n","      <td>1.341851</td>\n","      <td>1.659821</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20000 rows × 4 columns</p>\n","</div>"],"text/plain":["       Virial Mass  Virial Radius  Concentration  Vel. Dispersion\n","0        14.215638       3.054453       1.001863         2.984820\n","1        14.201124       3.049566       0.699512         2.947919\n","2        14.058426       3.001994       0.889922         2.907191\n","3        13.987175       2.978264       0.479754         2.879302\n","4        13.930796       2.959464       0.898464         2.872739\n","...            ...            ...            ...              ...\n","19995    10.283753       1.743768       1.431168         1.718585\n","19996    10.283753       1.743768       1.435631         1.678427\n","19997    10.283753       1.743768       1.133534         1.609914\n","19998    10.283753       1.743768       1.050305         1.632862\n","19999    10.283753       1.743768       1.341851         1.659821\n","\n","[20000 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"Vp8fWEfvHIpH","executionInfo":{"status":"ok","timestamp":1611768758757,"user_tz":300,"elapsed":448,"user":{"displayName":"Eduard Alexis Larranaga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64","userId":"04402438389940282602"}},"outputId":"b132f80b-5f20-4d4d-acc4-5b66c3b8bc1b"},"source":["halos.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Virial Mass</th>\n","      <th>Virial Radius</th>\n","      <th>Concentration</th>\n","      <th>Vel. Dispersion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>20000.000000</td>\n","      <td>20000.000000</td>\n","      <td>20000.000000</td>\n","      <td>20000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>10.781188</td>\n","      <td>1.909596</td>\n","      <td>1.144886</td>\n","      <td>1.831052</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.486944</td>\n","      <td>0.162315</td>\n","      <td>0.317982</td>\n","      <td>0.170236</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>10.283753</td>\n","      <td>1.743768</td>\n","      <td>0.002828</td>\n","      <td>1.548021</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>10.428944</td>\n","      <td>1.792181</td>\n","      <td>0.963105</td>\n","      <td>1.707315</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>10.632761</td>\n","      <td>1.860134</td>\n","      <td>1.126266</td>\n","      <td>1.787248</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>10.980821</td>\n","      <td>1.976139</td>\n","      <td>1.298915</td>\n","      <td>1.907881</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>14.215638</td>\n","      <td>3.054453</td>\n","      <td>3.029893</td>\n","      <td>2.984820</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Virial Mass  Virial Radius  Concentration  Vel. Dispersion\n","count  20000.000000   20000.000000   20000.000000     20000.000000\n","mean      10.781188       1.909596       1.144886         1.831052\n","std        0.486944       0.162315       0.317982         0.170236\n","min       10.283753       1.743768       0.002828         1.548021\n","25%       10.428944       1.792181       0.963105         1.707315\n","50%       10.632761       1.860134       1.126266         1.787248\n","75%       10.980821       1.976139       1.298915         1.907881\n","max       14.215638       3.054453       3.029893         2.984820"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"ZOGmcJ_j55c8"},"source":["Note that there are 20000 complete samples (i.e. there are no missing values!). \n","\n","**2. In order to visualize the data, use the `dataframe.hist()` method to plot the histogram for each feature.**"]},{"cell_type":"code","metadata":{"id":"8R9VkfkCOPOv"},"source":["#Plot a histogram for each halo property\n","#Use the function .hist that every pandas data frame has\n","#20 bins should work well\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P87vrtDstBaT"},"source":["This plot shows a histogram for each halo property. Some features, like the virial mass, the peak virial mass, and the virial radius start very high and then decline (they don't have a maximum). Some other features, like the half mass scale factor, the concentration, and the spin have a clear peak."]},{"cell_type":"markdown","metadata":{"id":"An2WjcANOPOw"},"source":["### Correlations in the data\n","We want to predict the halo concentration from the other features. It is helpful to first get an idea how to do this, by visualizing the datq, looking for correlations of each feature with the concentration. \n","\n","\n","**3. Create the Scatter Matrix for all the features**"]},{"cell_type":"code","metadata":{"id":"dGuQsiDN1rzQ"},"source":["attributes=['Feature 1', 'Feature 2', ...]\n","scatMatrix=pd.plotting.scatter_matrix(halos[attributes], figsize=(12,8))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kmr80GvZ70Fc"},"source":["**4. Use the `dataframe.corr()` method to obtain the correlation matrix of the dataframe.**"]},{"cell_type":"code","metadata":{"id":"ObklrSZ-F21w"},"source":["#Compute correlation matrix and show highest correlations for a given property\n","#The .corr() function gives you the correlation matrix\n","[Insert CODE Here] "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftjJmZlf8J3Y"},"source":["It is also possible to obtain the correlation coefficients of a particular feature with the rest of them by using a subscript with the name of the feature,"]},{"cell_type":"code","metadata":{"id":"qoClh--EGVmB"},"source":["#You can then print the result with the ['Name of Feature'] subscript\n","#If you add .sort_values() the results will get sorted\n","halos.corr()['Name of the Feature']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KtTNbH4mOPOx"},"source":["**It looks that 'concentration' has the highest (anti-)'correlation' with [Insert Feature], although the 'correlation' with [Insert Feature] is also significant.**\n"]},{"cell_type":"markdown","metadata":{"id":"D7-nhRJyi_lX"},"source":["**5 Create a scatter plot of the 'concentration' vs. the highest correlation feature.**"]},{"cell_type":"code","metadata":{"id":"Jkg8FlRTOPOx"},"source":["#Show scatter plot for highest correlation\n","halos.plot(kind='scatter', x='Insert Feature', y='Concentration', alpha=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eRt78cftOPOx"},"source":["### Preparing the data for machine learning\n","In order to train the linear regressor, we first have to produce a set of arrays with the relevant features.\n","\n","**6. Define the two arrays containing the 'concentration' and the highest correlation feature from the dataframe.** "]},{"cell_type":"code","metadata":{"id":"ujorPLR4OPOy"},"source":["#We cannot directly feed a Pandas data frame to scikit-learn.\n","#Therefore we need to transform our dataframe into a set of numpy arrays.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ihcKv-M6OPOw"},"source":["### Splitting the data into training and test sets\n","\n","In the next step, you will use the Scikit-Learn library to predict the halo 'concentration' from the other halo properties using a simple linear regression. \n","\n","As is common in machine learning, we will want to test how well our solutions generalise to other data sets.\n","It doesn't help us, if the algorithm learned how to model a feature for our training set very well, if it completely fails when used with a different data set.  \n","\n","Therefore, we need to split our data set into a training and a test set. \n","\n","**7. Split the dataset into a train and a test sets.**"]},{"cell_type":"code","metadata":{"id":"4R3RdGUUOPOw"},"source":["#Split train and test set randomly\n","#We use 20 per cent of the total data set as test set\n","#Use train_test_split to split the data\n","#Use random_state= with some integer to always have the same random numbers\n","X_train, X_test, y_train, y_test = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ni_DrztnOPOz"},"source":["### Training a linear regressor\n","Now that we have prepared the data, we can simply select a regressor and fit the data.\n","\n","**8. Train the linear model with the defined arrays**"]},{"cell_type":"code","metadata":{"id":"aPUthekNOPOz"},"source":["#Linear Regression\n","lin_reg = LinearRegression()\n","lin_reg.fit([INSERT HERE THE ARRAYS])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H0XgjCUZOPO6"},"source":["### Final evaluation on the test set\n","Now is time to test the linear model by computing the  prediction for the targets in the test set and meassure the final RMSE with respect to the knwon concentrations.\n","\n","**9. Calcuate the RMSE using the predictions and the test set**"]},{"cell_type":"code","metadata":{"id":"lkMJ9zSZOPOz"},"source":["#Compute Predictions and determine RMSE (=root mean squared error)\n","predictions = lin_reg.predict(...)\n","lin_mse = mean_squared_error(...)\n","lin_rmse = np.sqrt(...)\n","lin_rmse"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XWHziOspOPOz"},"source":["So we get a RMSE of about [...]dex, i.e. about [...]%. For this little work, this is not too bad. Let's see how it looks like! For this we plot the predicted concentrations vs. the labels (i.e. the real concentrations).\n","\n","**10. Plot the datapoints (train and test sets) together with the linear model** "]},{"cell_type":"code","metadata":{"id":"GBJZ1UFUOPOz"},"source":["#Plot prediction vs label\n","#plot predicted concentration vs. labels\n","#plot the 'perfect' result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dFAxJqZwRcR"},"source":["### A Multidimensional Linear Regression\n","\n","**11. Build a multilinear linear model to predict the 'concentration' from the two features with higher correlation coefficients.**"]},{"cell_type":"code","metadata":{"id":"K00GZUlNxRR2"},"source":[""],"execution_count":null,"outputs":[]}]}